{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Pairing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1jUsF_xGNAW"
      },
      "source": [
        "# get rid of the long sentence in question 2 at dataset (delete all)\n",
        "# update the numbers at the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eedf0B1fzRdh",
        "outputId": "1e2689eb-0871-4f7c-c1d5-77f27b212717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-15 21:42:15--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-10-15 21:42:15--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-10-15 21:42:15--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.08MB/s    in 6m 27s  \n",
            "\n",
            "2020-10-15 21:48:43 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLbzJVz0W-wy",
        "outputId": "a8a1c8d4-fb70-4143-80e6-e0803251a64a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6uNMJSbXMAW",
        "outputId": "aa9b0b64-302a-4b97-8280-5438b162dd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "!cp  drive/My\\ Drive/quora-question-pairs.zip quora-question-pairs.zip\n",
        "!unzip quora-question-pairs.zip\n",
        "!unzip test.csv.zip\n",
        "!unzip train.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  quora-question-pairs.zip\n",
            "  inflating: sample_submission.csv.zip  \n",
            "  inflating: test.csv                \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n",
            "Archive:  test.csv.zip\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CAmMc3PMoxm",
        "outputId": "4645bd30-559c-410f-928b-a447f66a0873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import string\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "import re\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynHkGVUizazc",
        "outputId": "f6906355-6706-4dbe-e385-c11742002843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file_name=\"glove.6B.300d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(file_name) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS_MyOg_NBQg"
      },
      "source": [
        "#STOPWORDS = set(stopwords.words('english'))\n",
        "# data preprocessing\n",
        "# 1)make text to lower\n",
        "# 2)remove punctuation\n",
        "# 3)remove numbers\n",
        "# 4)remove stopwords\n",
        "STOPWORDS = set(stopwords.words('english')) \n",
        "pattern_stopwords = re.compile(r'\\b(' + r'|'.join(STOPWORDS) + r')\\b')\n",
        "pattern_numbers = r'[0-9]'\n",
        "def dataprocessing(text):\n",
        "    text=text.lower()\n",
        "    text=re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text=re.sub(r'”', ' ', text)\n",
        "    text=re.sub(r'“', ' ', text)\n",
        "    text=re.sub(r'…', ' ', text)\n",
        "    text=re.sub(r'’', ' ', text)\n",
        "    text=re.sub(r'‘', ' ', text)\n",
        "    text = re.sub(pattern_numbers, ' ', text)\n",
        "    return re.sub(pattern_stopwords,' ',text)\n",
        "def apply_preprocessing(data:pd.DataFrame):\n",
        "  data[\"question1\"] = data[\"question1\"].astype(str)\n",
        "  data[\"question2\"] = data[\"question2\"].astype(str)\n",
        "  data[\"question1\"] = data[\"question1\"].apply(lambda text: dataprocessing(text))\n",
        "  data[\"question2\"] = data[\"question2\"].apply(lambda text: dataprocessing(text))\n",
        "  return data\n",
        "\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwGRbgOvfVKV"
      },
      "source": [
        "def get_input(data:pd.DataFrame):\n",
        "  word_tokenizer = Tokenizer()\n",
        "  data[\"count_1\"] =  [len(text) for text in data[\"question1\"]]\n",
        "  data[\"count_2\"] =  [len(text) for text in data[\"question2\"]]\n",
        "  data_filtered_1 = data[data['count_2']<=75]\n",
        "  tf2 = data_filtered_1[data_filtered_1['count_1']<=75]\n",
        "  word_tokenizer.fit_on_texts(data[\"question1\"]+data[\"question2\"])\n",
        "  vocab_length = len(word_tokenizer.word_index) + 1\n",
        "  dic=word_tokenizer.word_index\n",
        "  tf2[\"embedded_sentences_1\"] = word_tokenizer.texts_to_sequences(tf2[\"question1\"])\n",
        "  tf2[\"embedded_sentences_2\"] = word_tokenizer.texts_to_sequences(tf2[\"question2\"])\n",
        "  emb_pad_1 = pad_sequences(tf2[\"embedded_sentences_1\"],15, padding='post')\n",
        "  emb_pad_2 = pad_sequences(tf2[\"embedded_sentences_2\"],15, padding='post')\n",
        "  return dic,vocab_length,emb_pad_1,emb_pad_2,tf2 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmOBp07rhjxS",
        "outputId": "4f72943d-b144-4b6e-9b62-7743ded7acc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "'''data = pd.read_csv('train.csv')\n",
        "train = apply_preprocessing(data)\n",
        "train = train.sample(frac = 1)\n",
        "train_portion=int(0.9*train.shape[0])\n",
        "train_X = train[0:train_portion]\n",
        "word_tokenizer = Tokenizer()\n",
        "data[\"count_1\"] =  [len(text) for text in data[\"question1\"]]\n",
        "data[\"count_2\"] =  [len(text) for text in data[\"question2\"]]\n",
        "data_filtered_1 = data[data['count_2']<=75]\n",
        "tf2 = data_filtered_1[data_filtered_1['count_1']<=75]\n",
        "word_tokenizer.fit_on_texts(data[\"question1\"]+data[\"question2\"])\n",
        "vocab_length = len(word_tokenizer.word_index) + 1\n",
        "dic=word_tokenizer.word_index\n",
        "tf2[\"embedded_sentences_1\"] = word_tokenizer.texts_to_sequences(tf2[\"question1\"])\n",
        "tf2[\"embedded_sentences_2\"] = word_tokenizer.texts_to_sequences(tf2[\"question2\"])\n",
        "tf2[\"count_1\"] =  [len(text) for text in tf2[\"embedded_sentences_1\"]]\n",
        "tf2[\"count_2\"] =  [len(text) for text in tf2[\"embedded_sentences_2\"]]\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data = pd.read_csv(\\'train.csv\\')\\ntrain = apply_preprocessing(data)\\ntrain = train.sample(frac = 1)\\ntrain_portion=int(0.9*train.shape[0])\\ntrain_X = train[0:train_portion]\\nword_tokenizer = Tokenizer()\\ndata[\"count_1\"] =  [len(text) for text in data[\"question1\"]]\\ndata[\"count_2\"] =  [len(text) for text in data[\"question2\"]]\\ndata_filtered_1 = data[data[\\'count_2\\']<=75]\\ntf2 = data_filtered_1[data_filtered_1[\\'count_1\\']<=75]\\nword_tokenizer.fit_on_texts(data[\"question1\"]+data[\"question2\"])\\nvocab_length = len(word_tokenizer.word_index) + 1\\ndic=word_tokenizer.word_index\\ntf2[\"embedded_sentences_1\"] = word_tokenizer.texts_to_sequences(tf2[\"question1\"])\\ntf2[\"embedded_sentences_2\"] = word_tokenizer.texts_to_sequences(tf2[\"question2\"])\\ntf2[\"count_1\"] =  [len(text) for text in tf2[\"embedded_sentences_1\"]]\\ntf2[\"count_2\"] =  [len(text) for text in tf2[\"embedded_sentences_2\"]]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz5VWNKqmS0l"
      },
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "train = apply_preprocessing(data)\n",
        "train = train.sample(frac = 1)\n",
        "train_portion=int(0.35*train.shape[0])\n",
        "val_portion=int(0.05*train.shape[0])\n",
        "test_portion=int(0.05*train.shape[0])\n",
        "pos1=train_portion + val_portion\n",
        "last_pos=pos1 + test_portion\n",
        "train_X = train[0:train_portion]\n",
        "val_X = train[train_portion:pos1]\n",
        "test_X = train[pos1:last_pos]\n",
        "dic,vocab_length,train_emb_pad_1,train_emb_pad_2,train_tf2 = get_input(train_X)\n",
        "_,_,test_emb_pad_1,test_emb_pad_2,test_tf2 = get_input(test_X)\n",
        "_,_,val_emb_pad_1,val_emb_pad_2,val_tf2 = get_input(val_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6_L7zUhgb1g",
        "outputId": "8bbe1806-d51f-40a3-e6cb-b0207566ae99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "print(train_X.shape)\n",
        "train_X.hist(column=[\"count_1\"],figsize=[15,7],bins=5)\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(141501, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKX8pMJd9DTE",
        "outputId": "cafe2b1b-64af-42b3-f0c7-61ea1403d331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m = train_tf2.shape[0]\n",
        "print(m)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxRTjzpVzhxD",
        "outputId": "33023d1b-a5df-4348-d58a-b62e491e09be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "num_tokens = len(dic) + 2\n",
        "embedding_dim = 300\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in dic.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        #print(word)\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
        "print(num_tokens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 41072 words (9565 misses)\n",
            "50639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6588Obpzqi1"
      },
      "source": [
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lskvFlqb9nQR"
      },
      "source": [
        "input1 = tf.keras.Input(shape =(15,),name=\"input1\")\n",
        "input2 = tf.keras.Input(shape =(15,),name=\"input2\")\n",
        "X1 = embedding_layer(input1)\n",
        "X2 = embedding_layer(input2)\n",
        "X1 = layers.LSTM(128,return_sequences=True)(X1)\n",
        "X1 = layers.LSTM(128,)(X1)\n",
        "X2 = layers.LSTM(128,return_sequences=True)(X2)\n",
        "X2 = layers.LSTM(128)(X2)\n",
        "X =  layers.Concatenate(axis=1)([X1, X2])\n",
        "output = layers.Dense(1, activation='sigmoid')(X) \n",
        "model = Model(inputs=[input1,input2],outputs=output)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQkC7vdbBpDH",
        "outputId": "306ad8cb-ea91-43cb-ba35-98622142a240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "#opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input1 (InputLayer)             [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input2 (InputLayer)             [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           multiple             15191700    input1[0][0]                     \n",
            "                                                                 input2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 15, 128)      219648      embedding[2][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, 15, 128)      219648      embedding[3][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 128)          131584      lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 128)          131584      lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           lstm_5[0][0]                     \n",
            "                                                                 lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            257         concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 15,894,421\n",
            "Trainable params: 702,721\n",
            "Non-trainable params: 15,191,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7hfJoKW-D9u"
      },
      "source": [
        "print(train_emb_pad_1[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vuv1eQC0SYT",
        "outputId": "371e7d4d-5aea-4d07-963d-7ac30254edf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "model.fit([train_emb_pad_1,train_emb_pad_2], train_tf2[\"is_duplicate\"],batch_size =128, epochs=5, verbose=1,validation_data=[[val_emb_pad_1,val_emb_pad_2],val_tf2[\"is_duplicate\"]])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 110913 samples, validate on 15809 samples\n",
            "Epoch 1/5\n",
            "110913/110913 [==============================] - ETA: 0s - loss: 0.2117 - acc: 0.6687WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "110913/110913 [==============================] - 209s 2ms/sample - loss: 0.2117 - acc: 0.6687 - val_loss: 0.2497 - val_acc: 0.5920\n",
            "Epoch 2/5\n",
            "110913/110913 [==============================] - 206s 2ms/sample - loss: 0.1930 - acc: 0.7063 - val_loss: 0.2544 - val_acc: 0.5934\n",
            "Epoch 3/5\n",
            "110913/110913 [==============================] - 209s 2ms/sample - loss: 0.1802 - acc: 0.7313 - val_loss: 0.2529 - val_acc: 0.5876\n",
            "Epoch 4/5\n",
            "110913/110913 [==============================] - 211s 2ms/sample - loss: 0.1669 - acc: 0.7557 - val_loss: 0.2617 - val_acc: 0.5849\n",
            "Epoch 5/5\n",
            "110913/110913 [==============================] - 214s 2ms/sample - loss: 0.1510 - acc: 0.7849 - val_loss: 0.2742 - val_acc: 0.5787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe8472d5ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwYX1XsMaqqv",
        "outputId": "4274e134-514c-46b3-9258-a8bce06d4734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "loss, accuracy = model.evaluate([test_emb_pad_1,test_emb_pad_2],test_tf2[\"is_duplicate\"], verbose=1)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "print('loss: %f' % loss)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 58.843172\n",
            "loss: 0.268061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srR15G51YWHK"
      },
      "source": [
        "**Pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQM7Ya7sAwGq"
      },
      "source": [
        "#supports two segmentation algorithms, byte-pair-encoding (BPE)and unigram language model\n",
        "! pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXHLozzrYJzy"
      },
      "source": [
        "! wget https://storage.googleapis.com/xlnet/released_models/cased_L-12_H-768_A-12.zip\n",
        "! unzip cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QR1XKLCYQC3"
      },
      "source": [
        "! git clone https://github.com/zihangdai/xlnet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wv55WPDYSvJ"
      },
      "source": [
        "SCRIPTS_DIR = 'xlnet' #@param {type:\"string\"}\n",
        "DATA_DIR = 'train.csv' #@param {type:\"string\"}\n",
        "OUTPUT_DIR = 'proc_data/quora' #@param {type:\"string\"}\n",
        "PRETRAINED_MODEL_DIR = 'xlnet_cased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "CHECKPOINT_DIR = 'exp/quora' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1DFmmvwZCZI"
      },
      "source": [
        "train_command = \"python xlnet/run_classifier.py \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --eval_all_ckpt=True \\\n",
        "  --task_name=quora \\\n",
        "  --data_dir=\"+DATA_DIR+\" \\\n",
        "  --output_dir=\"+OUTPUT_DIR+\" \\\n",
        "  --model_dir=\"+CHECKPOINT_DIR+\" \\\n",
        "  --uncased=False \\\n",
        "  --spiece_model_file=\"+PRETRAINED_MODEL_DIR+\"/spiece.model \\\n",
        "  --model_config_path=\"+PRETRAINED_MODEL_DIR+\"/xlnet_config.json \\\n",
        "  --init_checkpoint=\"+PRETRAINED_MODEL_DIR+\"/xlnet_model.ckpt \\\n",
        "  --max_seq_length=128 \\\n",
        "  --train_batch_size=8 \\\n",
        "  --eval_batch_size=8 \\\n",
        "  --num_hosts=1 \\\n",
        "  --num_core_per_host=1 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --train_steps=4000 \\\n",
        "  --warmup_steps=500 \\\n",
        "  --save_steps=500 \\\n",
        "  --iterations=500\"\n",
        "\n",
        "! {train_command}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}