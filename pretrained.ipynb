{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pretrained",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "910514051cc84c30bbc785ae647a9d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_994f38cac6d64db79ed5497480fe8b7c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c786f6b961f4914bfd847495c944039",
              "IPY_MODEL_a0f5ee8727514aa9901442943ee5e571"
            ]
          }
        },
        "994f38cac6d64db79ed5497480fe8b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c786f6b961f4914bfd847495c944039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8ffab16fb664960bf75eb005e8f584e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7210738490764c29af7ff58308ced052"
          }
        },
        "a0f5ee8727514aa9901442943ee5e571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47fb959fafd640dab00d9f8d31c48353",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:03&lt;00:00, 264kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d82abd3422f423080b849ebb8cf8a56"
          }
        },
        "c8ffab16fb664960bf75eb005e8f584e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7210738490764c29af7ff58308ced052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47fb959fafd640dab00d9f8d31c48353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d82abd3422f423080b849ebb8cf8a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ed59628875c421c88c4cf7af2335e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d3440f34dd634285b83d2336e88013d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_77744c5d989d4677a63fc0d08a946514",
              "IPY_MODEL_b68d313205f04566be4177cf4d4fe99a"
            ]
          }
        },
        "d3440f34dd634285b83d2336e88013d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77744c5d989d4677a63fc0d08a946514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d75b4d18a41f467292798c273b53a7e2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e666a958ae11406796dc119c309b4725"
          }
        },
        "b68d313205f04566be4177cf4d4fe99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c53df7a616a7470287cc37229e0af06e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 562kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce21becb06614be98a8b178fb45c382b"
          }
        },
        "d75b4d18a41f467292798c273b53a7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e666a958ae11406796dc119c309b4725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c53df7a616a7470287cc37229e0af06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce21becb06614be98a8b178fb45c382b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "740ea6e48a5d4b1f8a8653c3a7fd22ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ce993ef5a8141d49a441c3788056a72",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eded28a244e945c99fb7d2bba91b95fa",
              "IPY_MODEL_531db42b57e74eaaa4c96eac45c108e4"
            ]
          }
        },
        "5ce993ef5a8141d49a441c3788056a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eded28a244e945c99fb7d2bba91b95fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a4451391ea34bb88e8574b9acc15ad0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc119c7cfb8f43a999a533603aabd2a9"
          }
        },
        "531db42b57e74eaaa4c96eac45c108e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03222db84f544dfb84c8ab51fe533a2b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [10:40&lt;00:00, 1.33s/B]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5ef44af575047ffbd07a7ce27e5766e"
          }
        },
        "8a4451391ea34bb88e8574b9acc15ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc119c7cfb8f43a999a533603aabd2a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03222db84f544dfb84c8ab51fe533a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5ef44af575047ffbd07a7ce27e5766e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0dbefee80c14b20a68fd8c0af399156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d211938e65a4513a135b9ed2cd35d2f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_853444f825ee4d8a87077858b46ad943",
              "IPY_MODEL_a4218f82068f4717887f7fa125be9343"
            ]
          }
        },
        "2d211938e65a4513a135b9ed2cd35d2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "853444f825ee4d8a87077858b46ad943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51d6128af2f942dfa72421c6065bd25f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69f38eb6f75946929c1eb3ad5d73258c"
          }
        },
        "a4218f82068f4717887f7fa125be9343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e20cc6b2541476cb0ec15d9728e5d20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:08&lt;00:00, 60.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abcccf3f81b3492aadc601e2c81ff1a6"
          }
        },
        "51d6128af2f942dfa72421c6065bd25f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69f38eb6f75946929c1eb3ad5d73258c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e20cc6b2541476cb0ec15d9728e5d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abcccf3f81b3492aadc601e2c81ff1a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BnukWQoDbRs"
      },
      "source": [
        "**Pre-trained:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYyuXbVMDWqU",
        "outputId": "09a43fc9-d58f-452a-b218-bcceee6fc91a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install keras-xlnet\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-xlnet\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/95/bbdc821aecf4b833d00da90cbbfb4f2b52dd18572fa9571daf9fc1166f0b/keras-xlnet-0.18.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-xlnet) (1.18.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-xlnet) (2.4.3)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 3.4MB/s \n",
            "\u001b[?25hCollecting keras-transformer>=0.30.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n",
            "Collecting keras-transformer-xl>=0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/32/2e8edd93cc3a687d5a63da5f81758e174aedfca948695caad6d9eb166845/keras-transformer-xl-0.12.0.tar.gz\n",
            "Collecting keras-trans-mask>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/96/33/f4dc20c8886ef72e10a0d2a6cd9e53f5cd683fc25b02c1c7e793978e8258/keras-trans-mask-0.4.0.tar.gz\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-xlnet) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-xlnet) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-xlnet) (3.13)\n",
            "Collecting keras-pos-embd>=0.11.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.27.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.14.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n",
            "Collecting keras-adaptive-softmax>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/7c/c58a76f3e9fdfb6252eaa18aac1dcbf011eac96c6de3adbb47db318567dd/keras-adaptive-softmax-0.6.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-xlnet) (1.15.0)\n",
            "Collecting keras-self-attention==0.46.0\n",
            "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
            "Building wheels for collected packages: keras-xlnet, keras-transformer, keras-transformer-xl, keras-trans-mask, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-adaptive-softmax, keras-self-attention\n",
            "  Building wheel for keras-xlnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-xlnet: filename=keras_xlnet-0.18.0-cp36-none-any.whl size=44299 sha256=24195119491f27e1c49de654b9ba99b005c605215e91458995b48e6fc1ce6ab2\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/fa/2d/68fed1da83d148f8cceea78242835efdd9bdd201620cba67b1\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp36-none-any.whl size=12942 sha256=08d18332a460b7b23922658e902255ad2b2d466665f28327862846207d59bbab\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n",
            "  Building wheel for keras-transformer-xl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer-xl: filename=keras_transformer_xl-0.12.0-cp36-none-any.whl size=20616 sha256=31425c9fd561c648cad8041dfb51b5cfbdb89287c8219afd279fa0b31deccb79\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/67/8e/3dcd391ed60f09ca50059102cb829d21d54eba18b61034d33a\n",
            "  Building wheel for keras-trans-mask (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-trans-mask: filename=keras_trans_mask-0.4.0-cp36-none-any.whl size=4236 sha256=0f8ec95c6b437531f2700d1079d4a8c198e1184a74269f3491ca7d84152eb85e\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/1c/8b/66d7549aee3573eccfdd06ead92590986048327a882ef975ad\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=290f6c6560fa6dca9c64a71ae3b714d2e3b6eced075d603b4733916a7c77256d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15612 sha256=9ae8f79681e2e8d14a133232fe358975adc131f0f62b51e5dc2683334e9fd387\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=92388085f99ae2adebba4b184cff5b882d73e6ea40a49e280274cdc9ab538561\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5626 sha256=abc4c3a6aee718ef9105dc109b0be031a4bf342ef3a0807d2961de454e9d4d51\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp36-none-any.whl size=4559 sha256=d01fe9052637fed31ace68d8ba936f77bb2f69d2d535394d629e9311f1474b9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n",
            "  Building wheel for keras-adaptive-softmax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-adaptive-softmax: filename=keras_adaptive_softmax-0.6.0-cp36-none-any.whl size=20242 sha256=73303f778ca92d8a7cbf35d67804612e70a7443f9a5238a404d220824525e522\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/80/55/8516bf7477422d8790431f6c96a6f10f8cc7ce6147603e83a0\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=41f72bc022e2653f98a960bb375914c40434ab2a252386feb0c96519167990e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
            "Successfully built keras-xlnet keras-transformer keras-transformer-xl keras-trans-mask keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-adaptive-softmax keras-self-attention\n",
            "Installing collected packages: sentencepiece, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-adaptive-softmax, keras-transformer-xl, keras-trans-mask, keras-xlnet\n",
            "Successfully installed keras-adaptive-softmax-0.6.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-trans-mask-0.4.0 keras-transformer-0.38.0 keras-transformer-xl-0.12.0 keras-xlnet-0.18.0 sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua9-kr9WD4ij",
        "outputId": "64ba50fc-1661-418c-f7e7-744aa7936384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgHrEwT3IeIl",
        "outputId": "67cb12b2-0ec3-4a3a-cc8a-29335c9bc0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "! wget https://storage.googleapis.com/xlnet/released_models/cased_L-12_H-768_A-12.zip\n",
        "! unzip cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-15 17:08:24--  https://storage.googleapis.com/xlnet/released_models/cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 74.125.23.128, 74.125.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 433638019 (414M) [application/zip]\n",
            "Saving to: â€˜cased_L-12_H-768_A-12.zipâ€™\n",
            "\n",
            "cased_L-12_H-768_A- 100%[===================>] 413.55M  59.7MB/s    in 8.1s    \n",
            "\n",
            "2020-10-15 17:08:33 (51.1 MB/s) - â€˜cased_L-12_H-768_A-12.zipâ€™ saved [433638019/433638019]\n",
            "\n",
            "Archive:  cased_L-12_H-768_A-12.zip\n",
            "   creating: xlnet_cased_L-12_H-768_A-12/\n",
            "  inflating: xlnet_cased_L-12_H-768_A-12/xlnet_model.ckpt.index  \n",
            "  inflating: xlnet_cased_L-12_H-768_A-12/xlnet_model.ckpt.data-00000-of-00001  \n",
            "  inflating: xlnet_cased_L-12_H-768_A-12/spiece.model  \n",
            "  inflating: xlnet_cased_L-12_H-768_A-12/xlnet_model.ckpt.meta  \n",
            "  inflating: xlnet_cased_L-12_H-768_A-12/xlnet_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX9Z6NhqIh7d",
        "outputId": "583dc26f-ebf4-45e9-d61a-aa13df2ca295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "! git clone https://github.com/zihangdai/xlnet.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'xlnet'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Total 122 (delta 0), reused 0 (delta 0), pack-reused 122\u001b[K\n",
            "Receiving objects: 100% (122/122), 2.92 MiB | 2.58 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gsJACXcF71N",
        "outputId": "3e1d205c-531d-4ff7-d2bf-f73a08b00c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "import os\n",
        "from keras_xlnet import Tokenizer, load_trained_model_from_checkpoint, ATTENTION_TYPE_BI\n",
        "\n",
        "checkpoint_path = 'xlnet_cased_L-12_H-768_A-12'\n",
        "\n",
        "tokenizer = Tokenizer(os.path.join(checkpoint_path, 'spiece.model'))\n",
        "model = load_trained_model_from_checkpoint(\n",
        "    config_path=os.path.join(checkpoint_path, 'xlnet_config.json'),\n",
        "    checkpoint_path=os.path.join(checkpoint_path, 'xlnet_model.ckpt'),\n",
        "    batch_size=16,\n",
        "    memory_len=512,\n",
        "    target_len=128,\n",
        "    in_train_phase=True,\n",
        "    attention_type=ATTENTION_TYPE_BI,\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras_transformer_xl/memory.py:72: calling Layer.add_update (from tensorflow.python.keras.engine.base_layer) with inputs is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`inputs` is now automatically inferred\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Token (EmbeddingRet)      [(None, 128, 768), ( 24576000    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Masking (CreateMask)            (None, 128)          0           Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Token-Masked (RestoreMask (None, 128, 768)     0           Embed-Token[0][0]                \n",
            "                                                                 Masking[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Input-Memory-Length (InputLayer [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Mask (InputLayer)         [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Memory-0 (Memory)               (None, None, 768)    7864320     Embed-Token-Masked[0][0]         \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Mask (MaskEmbedding)      (None, 128, 768)     768         Embed-Token-Masked[0][0]         \n",
            "                                                                 Input-Mask[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-1 (RelativeSegmen [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Pos (PositionalEmbedding) (None, None, 768)    0           Embed-Token-Masked[0][0]         \n",
            "                                                                 Memory-0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-1 (RelativeBias)  [(768,), (768,)]     1536        Memory-0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-1 (SegmentBias)    (768,)               768         Memory-0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Permutation (PermutationMask)   [(None, None, None), 0           Embed-Token-Masked[0][0]         \n",
            "                                                                 Memory-0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention-1 (RelativePartialMul (None, None, 768)    2949120     Embed-Token-Masked[0][0]         \n",
            "                                                                 Embed-Token-Masked[0][0]         \n",
            "                                                                 Memory-0[0][0]                   \n",
            "                                                                 Embed-Segment-1[0][0]            \n",
            "                                                                 Embed-Segment-1[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-1[0][0]            \n",
            "                                                                 Relative-Bias-1[0][1]            \n",
            "                                                                 Segment-Bias-1[0][0]             \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 Embed-Mask[0][0]                 \n",
            "                                                                 Embed-Token-Masked[0][0]         \n",
            "                                                                 Memory-0[0][0]                   \n",
            "                                                                 Embed-Segment-1[0][0]            \n",
            "                                                                 Embed-Segment-1[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-1[0][0]            \n",
            "                                                                 Relative-Bias-1[0][1]            \n",
            "                                                                 Segment-Bias-1[0][0]             \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-1 (Add)      (None, 128, 768)     0           Embed-Token-Masked[0][0]         \n",
            "                                                                 Attention-1[0][0]                \n",
            "                                                                 Embed-Mask[0][0]                 \n",
            "                                                                 Attention-1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-1 (LayerNormal (None, 128, 768)     1536        Attention-Residual-1[0][0]       \n",
            "                                                                 Attention-Residual-1[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-1 (FeedForward)     (None, 128, 768)     4722432     Attention-Normal-1[0][0]         \n",
            "                                                                 Attention-Normal-1[1][0]         \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-1 (Add)    (None, 128, 768)     0           Attention-Normal-1[0][0]         \n",
            "                                                                 FeedForward-1[0][0]              \n",
            "                                                                 Attention-Normal-1[1][0]         \n",
            "                                                                 FeedForward-1[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-1 (LayerNorm (None, 128, 768)     1536        FeedForward-Residual-1[0][0]     \n",
            "                                                                 FeedForward-Residual-1[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Memory-1 (Memory)               (None, None, 768)    7864320     FeedForward-Normal-1[0][0]       \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-2 (RelativeSegmen [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-2 (RelativeBias)  [(768,), (768,)]     1536        Memory-1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-2 (SegmentBias)    (768,)               768         Memory-1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention-2 (RelativePartialMul (None, None, 768)    2949120     FeedForward-Normal-1[0][0]       \n",
            "                                                                 FeedForward-Normal-1[0][0]       \n",
            "                                                                 Memory-1[0][0]                   \n",
            "                                                                 Embed-Segment-2[0][0]            \n",
            "                                                                 Embed-Segment-2[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-2[0][0]            \n",
            "                                                                 Relative-Bias-2[0][1]            \n",
            "                                                                 Segment-Bias-2[0][0]             \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 FeedForward-Normal-1[1][0]       \n",
            "                                                                 FeedForward-Normal-1[0][0]       \n",
            "                                                                 Memory-1[0][0]                   \n",
            "                                                                 Embed-Segment-2[0][0]            \n",
            "                                                                 Embed-Segment-2[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-2[0][0]            \n",
            "                                                                 Relative-Bias-2[0][1]            \n",
            "                                                                 Segment-Bias-2[0][0]             \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-2 (Add)      (None, 128, 768)     0           FeedForward-Normal-1[0][0]       \n",
            "                                                                 Attention-2[0][0]                \n",
            "                                                                 FeedForward-Normal-1[1][0]       \n",
            "                                                                 Attention-2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-2 (LayerNormal (None, 128, 768)     1536        Attention-Residual-2[0][0]       \n",
            "                                                                 Attention-Residual-2[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-2 (FeedForward)     (None, 128, 768)     4722432     Attention-Normal-2[0][0]         \n",
            "                                                                 Attention-Normal-2[1][0]         \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-2 (Add)    (None, 128, 768)     0           Attention-Normal-2[0][0]         \n",
            "                                                                 FeedForward-2[0][0]              \n",
            "                                                                 Attention-Normal-2[1][0]         \n",
            "                                                                 FeedForward-2[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-2 (LayerNorm (None, 128, 768)     1536        FeedForward-Residual-2[0][0]     \n",
            "                                                                 FeedForward-Residual-2[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Memory-2 (Memory)               (None, None, 768)    7864320     FeedForward-Normal-2[0][0]       \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-3 (RelativeSegmen [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-3 (RelativeBias)  [(768,), (768,)]     1536        Memory-2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-3 (SegmentBias)    (768,)               768         Memory-2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention-3 (RelativePartialMul (None, None, 768)    2949120     FeedForward-Normal-2[0][0]       \n",
            "                                                                 FeedForward-Normal-2[0][0]       \n",
            "                                                                 Memory-2[0][0]                   \n",
            "                                                                 Embed-Segment-3[0][0]            \n",
            "                                                                 Embed-Segment-3[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-3[0][0]            \n",
            "                                                                 Relative-Bias-3[0][1]            \n",
            "                                                                 Segment-Bias-3[0][0]             \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 FeedForward-Normal-2[1][0]       \n",
            "                                                                 FeedForward-Normal-2[0][0]       \n",
            "                                                                 Memory-2[0][0]                   \n",
            "                                                                 Embed-Segment-3[0][0]            \n",
            "                                                                 Embed-Segment-3[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-3[0][0]            \n",
            "                                                                 Relative-Bias-3[0][1]            \n",
            "                                                                 Segment-Bias-3[0][0]             \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-3 (Add)      (None, 128, 768)     0           FeedForward-Normal-2[0][0]       \n",
            "                                                                 Attention-3[0][0]                \n",
            "                                                                 FeedForward-Normal-2[1][0]       \n",
            "                                                                 Attention-3[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-3 (LayerNormal (None, 128, 768)     1536        Attention-Residual-3[0][0]       \n",
            "                                                                 Attention-Residual-3[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-3 (FeedForward)     (None, 128, 768)     4722432     Attention-Normal-3[0][0]         \n",
            "                                                                 Attention-Normal-3[1][0]         \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-3 (Add)    (None, 128, 768)     0           Attention-Normal-3[0][0]         \n",
            "                                                                 FeedForward-3[0][0]              \n",
            "                                                                 Attention-Normal-3[1][0]         \n",
            "                                                                 FeedForward-3[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-3 (LayerNorm (None, 128, 768)     1536        FeedForward-Residual-3[0][0]     \n",
            "                                                                 FeedForward-Residual-3[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Memory-3 (Memory)               (None, None, 768)    7864320     FeedForward-Normal-3[0][0]       \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-4 (RelativeSegmen [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-4 (RelativeBias)  [(768,), (768,)]     1536        Memory-3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-4 (SegmentBias)    (768,)               768         Memory-3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention-4 (RelativePartialMul (None, None, 768)    2949120     FeedForward-Normal-3[0][0]       \n",
            "                                                                 FeedForward-Normal-3[0][0]       \n",
            "                                                                 Memory-3[0][0]                   \n",
            "                                                                 Embed-Segment-4[0][0]            \n",
            "                                                                 Embed-Segment-4[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-4[0][0]            \n",
            "                                                                 Relative-Bias-4[0][1]            \n",
            "                                                                 Segment-Bias-4[0][0]             \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 FeedForward-Normal-3[1][0]       \n",
            "                                                                 FeedForward-Normal-3[0][0]       \n",
            "                                                                 Memory-3[0][0]                   \n",
            "                                                                 Embed-Segment-4[0][0]            \n",
            "                                                                 Embed-Segment-4[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-4[0][0]            \n",
            "                                                                 Relative-Bias-4[0][1]            \n",
            "                                                                 Segment-Bias-4[0][0]             \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-4 (Add)      (None, 128, 768)     0           FeedForward-Normal-3[0][0]       \n",
            "                                                                 Attention-4[0][0]                \n",
            "                                                                 FeedForward-Normal-3[1][0]       \n",
            "                                                                 Attention-4[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-4 (LayerNormal (None, 128, 768)     1536        Attention-Residual-4[0][0]       \n",
            "                                                                 Attention-Residual-4[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-4 (FeedForward)     (None, 128, 768)     4722432     Attention-Normal-4[0][0]         \n",
            "                                                                 Attention-Normal-4[1][0]         \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-4 (Add)    (None, 128, 768)     0           Attention-Normal-4[0][0]         \n",
            "                                                                 FeedForward-4[0][0]              \n",
            "                                                                 Attention-Normal-4[1][0]         \n",
            "                                                                 FeedForward-4[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-4 (LayerNorm (None, 128, 768)     1536        FeedForward-Residual-4[0][0]     \n",
            "                                                                 FeedForward-Residual-4[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Memory-4 (Memory)               (None, None, 768)    7864320     FeedForward-Normal-4[0][0]       \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-5 (RelativeSegmen [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-5 (RelativeBias)  [(768,), (768,)]     1536        Memory-4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-5 (SegmentBias)    (768,)               768         Memory-4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention-5 (RelativePartialMul (None, None, 768)    2949120     FeedForward-Normal-4[0][0]       \n",
            "                                                                 FeedForward-Normal-4[0][0]       \n",
            "                                                                 Memory-4[0][0]                   \n",
            "                                                                 Embed-Segment-5[0][0]            \n",
            "                                                                 Embed-Segment-5[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-5[0][0]            \n",
            "                                                                 Relative-Bias-5[0][1]            \n",
            "                                                                 Segment-Bias-5[0][0]             \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 FeedForward-Normal-4[1][0]       \n",
            "                                                                 FeedForward-Normal-4[0][0]       \n",
            "                                                                 Memory-4[0][0]                   \n",
            "                                                                 Embed-Segment-5[0][0]            \n",
            "                                                                 Embed-Segment-5[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-5[0][0]            \n",
            "                                                                 Relative-Bias-5[0][1]            \n",
            "                                                                 Segment-Bias-5[0][0]             \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-5 (Add)      (None, 128, 768)     0           FeedForward-Normal-4[0][0]       \n",
            "                                                                 Attention-5[0][0]                \n",
            "                                                                 FeedForward-Normal-4[1][0]       \n",
            "                                                                 Attention-5[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-5 (LayerNormal (None, 128, 768)     1536        Attention-Residual-5[0][0]       \n",
            "                                                                 Attention-Residual-5[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-5 (FeedForward)     (None, 128, 768)     4722432     Attention-Normal-5[0][0]         \n",
            "                                                                 Attention-Normal-5[1][0]         \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-5 (Add)    (None, 128, 768)     0           Attention-Normal-5[0][0]         \n",
            "                                                                 FeedForward-5[0][0]              \n",
            "                                                                 Attention-Normal-5[1][0]         \n",
            "                                                                 FeedForward-5[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-5 (LayerNorm (None, 128, 768)     1536        FeedForward-Residual-5[0][0]     \n",
            "                                                                 FeedForward-Residual-5[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Memory-5 (Memory)               (None, None, 768)    7864320     FeedForward-Normal-5[0][0]       \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-6 (RelativeSegmen [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-6 (RelativeBias)  [(768,), (768,)]     1536        Memory-5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-6 (SegmentBias)    (768,)               768         Memory-5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention-6 (RelativePartialMul (None, None, 768)    2949120     FeedForward-Normal-5[0][0]       \n",
            "                                                                 FeedForward-Normal-5[0][0]       \n",
            "                                                                 Memory-5[0][0]                   \n",
            "                                                                 Embed-Segment-6[0][0]            \n",
            "                                                                 Embed-Segment-6[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-6[0][0]            \n",
            "                                                                 Relative-Bias-6[0][1]            \n",
            "                                                                 Segment-Bias-6[0][0]             \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 FeedForward-Normal-5[1][0]       \n",
            "                                                                 FeedForward-Normal-5[0][0]       \n",
            "                                                                 Memory-5[0][0]                   \n",
            "                                                                 Embed-Segment-6[0][0]            \n",
            "                                                                 Embed-Segment-6[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-6[0][0]            \n",
            "                                                                 Relative-Bias-6[0][1]            \n",
            "                                                                 Segment-Bias-6[0][0]             \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-6 (Add)      (None, 128, 768)     0           FeedForward-Normal-5[0][0]       \n",
            "                                                                 Attention-6[0][0]                \n",
            "                                                                 FeedForward-Normal-5[1][0]       \n",
            "                                                                 Attention-6[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-6 (LayerNormal (None, 128, 768)     1536        Attention-Residual-6[0][0]       \n",
            "                                                                 Attention-Residual-6[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-6 (FeedForward)     (None, 128, 768)     4722432     Attention-Normal-6[0][0]         \n",
            "                                                                 Attention-Normal-6[1][0]         \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-6 (Add)    (None, 128, 768)     0           Attention-Normal-6[0][0]         \n",
            "                                                                 FeedForward-6[0][0]              \n",
            "                                                                 Attention-Normal-6[1][0]         \n",
            "                                                                 FeedForward-6[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-6 (LayerNorm (None, 128, 768)     1536        FeedForward-Residual-6[0][0]     \n",
            "                                                                 FeedForward-Residual-6[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Memory-6 (Memory)               (None, None, 768)    7864320     FeedForward-Normal-6[0][0]       \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-7 (RelativeSegmen [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-7 (RelativeBias)  [(768,), (768,)]     1536        Memory-6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-7 (SegmentBias)    (768,)               768         Memory-6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention-7 (RelativePartialMul (None, None, 768)    2949120     FeedForward-Normal-6[0][0]       \n",
            "                                                                 FeedForward-Normal-6[0][0]       \n",
            "                                                                 Memory-6[0][0]                   \n",
            "                                                                 Embed-Segment-7[0][0]            \n",
            "                                                                 Embed-Segment-7[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-7[0][0]            \n",
            "                                                                 Relative-Bias-7[0][1]            \n",
            "                                                                 Segment-Bias-7[0][0]             \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 FeedForward-Normal-6[1][0]       \n",
            "                                                                 FeedForward-Normal-6[0][0]       \n",
            "                                                                 Memory-6[0][0]                   \n",
            "                                                                 Embed-Segment-7[0][0]            \n",
            "                                                                 Embed-Segment-7[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-7[0][0]            \n",
            "                                                                 Relative-Bias-7[0][1]            \n",
            "                                                                 Segment-Bias-7[0][0]             \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-7 (Add)      (None, 128, 768)     0           FeedForward-Normal-6[0][0]       \n",
            "                                                                 Attention-7[0][0]                \n",
            "                                                                 FeedForward-Normal-6[1][0]       \n",
            "                                                                 Attention-7[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-7 (LayerNormal (None, 128, 768)     1536        Attention-Residual-7[0][0]       \n",
            "                                                                 Attention-Residual-7[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-7 (FeedForward)     (None, 128, 768)     4722432     Attention-Normal-7[0][0]         \n",
            "                                                                 Attention-Normal-7[1][0]         \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-7 (Add)    (None, 128, 768)     0           Attention-Normal-7[0][0]         \n",
            "                                                                 FeedForward-7[0][0]              \n",
            "                                                                 Attention-Normal-7[1][0]         \n",
            "                                                                 FeedForward-7[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-7 (LayerNorm (None, 128, 768)     1536        FeedForward-Residual-7[0][0]     \n",
            "                                                                 FeedForward-Residual-7[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Memory-7 (Memory)               (None, None, 768)    7864320     FeedForward-Normal-7[0][0]       \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-8 (RelativeSegmen [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-8 (RelativeBias)  [(768,), (768,)]     1536        Memory-7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-8 (SegmentBias)    (768,)               768         Memory-7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention-8 (RelativePartialMul (None, None, 768)    2949120     FeedForward-Normal-7[0][0]       \n",
            "                                                                 FeedForward-Normal-7[0][0]       \n",
            "                                                                 Memory-7[0][0]                   \n",
            "                                                                 Embed-Segment-8[0][0]            \n",
            "                                                                 Embed-Segment-8[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-8[0][0]            \n",
            "                                                                 Relative-Bias-8[0][1]            \n",
            "                                                                 Segment-Bias-8[0][0]             \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 FeedForward-Normal-7[1][0]       \n",
            "                                                                 FeedForward-Normal-7[0][0]       \n",
            "                                                                 Memory-7[0][0]                   \n",
            "                                                                 Embed-Segment-8[0][0]            \n",
            "                                                                 Embed-Segment-8[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-8[0][0]            \n",
            "                                                                 Relative-Bias-8[0][1]            \n",
            "                                                                 Segment-Bias-8[0][0]             \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-8 (Add)      (None, 128, 768)     0           FeedForward-Normal-7[0][0]       \n",
            "                                                                 Attention-8[0][0]                \n",
            "                                                                 FeedForward-Normal-7[1][0]       \n",
            "                                                                 Attention-8[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-8 (LayerNormal (None, 128, 768)     1536        Attention-Residual-8[0][0]       \n",
            "                                                                 Attention-Residual-8[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-8 (FeedForward)     (None, 128, 768)     4722432     Attention-Normal-8[0][0]         \n",
            "                                                                 Attention-Normal-8[1][0]         \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-8 (Add)    (None, 128, 768)     0           Attention-Normal-8[0][0]         \n",
            "                                                                 FeedForward-8[0][0]              \n",
            "                                                                 Attention-Normal-8[1][0]         \n",
            "                                                                 FeedForward-8[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-8 (LayerNorm (None, 128, 768)     1536        FeedForward-Residual-8[0][0]     \n",
            "                                                                 FeedForward-Residual-8[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Memory-8 (Memory)               (None, None, 768)    7864320     FeedForward-Normal-8[0][0]       \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-9 (RelativeSegmen [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-9 (RelativeBias)  [(768,), (768,)]     1536        Memory-8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-9 (SegmentBias)    (768,)               768         Memory-8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention-9 (RelativePartialMul (None, None, 768)    2949120     FeedForward-Normal-8[0][0]       \n",
            "                                                                 FeedForward-Normal-8[0][0]       \n",
            "                                                                 Memory-8[0][0]                   \n",
            "                                                                 Embed-Segment-9[0][0]            \n",
            "                                                                 Embed-Segment-9[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-9[0][0]            \n",
            "                                                                 Relative-Bias-9[0][1]            \n",
            "                                                                 Segment-Bias-9[0][0]             \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 FeedForward-Normal-8[1][0]       \n",
            "                                                                 FeedForward-Normal-8[0][0]       \n",
            "                                                                 Memory-8[0][0]                   \n",
            "                                                                 Embed-Segment-9[0][0]            \n",
            "                                                                 Embed-Segment-9[0][1]            \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-9[0][0]            \n",
            "                                                                 Relative-Bias-9[0][1]            \n",
            "                                                                 Segment-Bias-9[0][0]             \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-9 (Add)      (None, 128, 768)     0           FeedForward-Normal-8[0][0]       \n",
            "                                                                 Attention-9[0][0]                \n",
            "                                                                 FeedForward-Normal-8[1][0]       \n",
            "                                                                 Attention-9[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-9 (LayerNormal (None, 128, 768)     1536        Attention-Residual-9[0][0]       \n",
            "                                                                 Attention-Residual-9[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-9 (FeedForward)     (None, 128, 768)     4722432     Attention-Normal-9[0][0]         \n",
            "                                                                 Attention-Normal-9[1][0]         \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-9 (Add)    (None, 128, 768)     0           Attention-Normal-9[0][0]         \n",
            "                                                                 FeedForward-9[0][0]              \n",
            "                                                                 Attention-Normal-9[1][0]         \n",
            "                                                                 FeedForward-9[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-9 (LayerNorm (None, 128, 768)     1536        FeedForward-Residual-9[0][0]     \n",
            "                                                                 FeedForward-Residual-9[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Memory-9 (Memory)               (None, None, 768)    7864320     FeedForward-Normal-9[0][0]       \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-10 (RelativeSegme [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-10 (RelativeBias) [(768,), (768,)]     1536        Memory-9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-10 (SegmentBias)   (768,)               768         Memory-9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Attention-10 (RelativePartialMu (None, None, 768)    2949120     FeedForward-Normal-9[0][0]       \n",
            "                                                                 FeedForward-Normal-9[0][0]       \n",
            "                                                                 Memory-9[0][0]                   \n",
            "                                                                 Embed-Segment-10[0][0]           \n",
            "                                                                 Embed-Segment-10[0][1]           \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-10[0][0]           \n",
            "                                                                 Relative-Bias-10[0][1]           \n",
            "                                                                 Segment-Bias-10[0][0]            \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 FeedForward-Normal-9[1][0]       \n",
            "                                                                 FeedForward-Normal-9[0][0]       \n",
            "                                                                 Memory-9[0][0]                   \n",
            "                                                                 Embed-Segment-10[0][0]           \n",
            "                                                                 Embed-Segment-10[0][1]           \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-10[0][0]           \n",
            "                                                                 Relative-Bias-10[0][1]           \n",
            "                                                                 Segment-Bias-10[0][0]            \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-10 (Add)     (None, 128, 768)     0           FeedForward-Normal-9[0][0]       \n",
            "                                                                 Attention-10[0][0]               \n",
            "                                                                 FeedForward-Normal-9[1][0]       \n",
            "                                                                 Attention-10[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-10 (LayerNorma (None, 128, 768)     1536        Attention-Residual-10[0][0]      \n",
            "                                                                 Attention-Residual-10[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-10 (FeedForward)    (None, 128, 768)     4722432     Attention-Normal-10[0][0]        \n",
            "                                                                 Attention-Normal-10[1][0]        \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-10 (Add)   (None, 128, 768)     0           Attention-Normal-10[0][0]        \n",
            "                                                                 FeedForward-10[0][0]             \n",
            "                                                                 Attention-Normal-10[1][0]        \n",
            "                                                                 FeedForward-10[1][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-10 (LayerNor (None, 128, 768)     1536        FeedForward-Residual-10[0][0]    \n",
            "                                                                 FeedForward-Residual-10[1][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Memory-10 (Memory)              (None, None, 768)    7864320     FeedForward-Normal-10[0][0]      \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-11 (RelativeSegme [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-11 (RelativeBias) [(768,), (768,)]     1536        Memory-10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-11 (SegmentBias)   (768,)               768         Memory-10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Attention-11 (RelativePartialMu (None, None, 768)    2949120     FeedForward-Normal-10[0][0]      \n",
            "                                                                 FeedForward-Normal-10[0][0]      \n",
            "                                                                 Memory-10[0][0]                  \n",
            "                                                                 Embed-Segment-11[0][0]           \n",
            "                                                                 Embed-Segment-11[0][1]           \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-11[0][0]           \n",
            "                                                                 Relative-Bias-11[0][1]           \n",
            "                                                                 Segment-Bias-11[0][0]            \n",
            "                                                                 Permutation[0][0]                \n",
            "                                                                 FeedForward-Normal-10[1][0]      \n",
            "                                                                 FeedForward-Normal-10[0][0]      \n",
            "                                                                 Memory-10[0][0]                  \n",
            "                                                                 Embed-Segment-11[0][0]           \n",
            "                                                                 Embed-Segment-11[0][1]           \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-11[0][0]           \n",
            "                                                                 Relative-Bias-11[0][1]           \n",
            "                                                                 Segment-Bias-11[0][0]            \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-11 (Add)     (None, 128, 768)     0           FeedForward-Normal-10[0][0]      \n",
            "                                                                 Attention-11[0][0]               \n",
            "                                                                 FeedForward-Normal-10[1][0]      \n",
            "                                                                 Attention-11[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-11 (LayerNorma (None, 128, 768)     1536        Attention-Residual-11[0][0]      \n",
            "                                                                 Attention-Residual-11[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-11 (FeedForward)    (None, 128, 768)     4722432     Attention-Normal-11[0][0]        \n",
            "                                                                 Attention-Normal-11[1][0]        \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-11 (Add)   (None, 128, 768)     0           Attention-Normal-11[0][0]        \n",
            "                                                                 FeedForward-11[0][0]             \n",
            "                                                                 Attention-Normal-11[1][0]        \n",
            "                                                                 FeedForward-11[1][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-11 (LayerNor (None, 128, 768)     1536        FeedForward-Residual-11[0][0]    \n",
            "                                                                 FeedForward-Residual-11[1][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Memory-11 (Memory)              (None, None, 768)    7864320     FeedForward-Normal-11[0][0]      \n",
            "                                                                 Input-Memory-Length[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Embed-Segment-12 (RelativeSegme [(None, 128, None, 2 1536        Input-Segment[0][0]              \n",
            "                                                                 Memory-11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Relative-Bias-12 (RelativeBias) [(768,), (768,)]     1536        Memory-11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Segment-Bias-12 (SegmentBias)   (768,)               768         Memory-11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Attention-12 (RelativePartialMu (None, None, 768)    2949120     FeedForward-Normal-11[1][0]      \n",
            "                                                                 FeedForward-Normal-11[0][0]      \n",
            "                                                                 Memory-11[0][0]                  \n",
            "                                                                 Embed-Segment-12[0][0]           \n",
            "                                                                 Embed-Segment-12[0][1]           \n",
            "                                                                 Embed-Pos[0][0]                  \n",
            "                                                                 Relative-Bias-12[0][0]           \n",
            "                                                                 Relative-Bias-12[0][1]           \n",
            "                                                                 Segment-Bias-12[0][0]            \n",
            "                                                                 Permutation[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Residual-12 (Add)     (None, 128, 768)     0           FeedForward-Normal-11[1][0]      \n",
            "                                                                 Attention-12[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Attention-Normal-12 (LayerNorma (None, 128, 768)     1536        Attention-Residual-12[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-12 (FeedForward)    (None, 128, 768)     4722432     Attention-Normal-12[1][0]        \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Residual-12 (Add)   (None, 128, 768)     0           Attention-Normal-12[1][0]        \n",
            "                                                                 FeedForward-12[1][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FeedForward-Normal-12 (LayerNor (None, 128, 768)     1536        FeedForward-Residual-12[1][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Softmax (EmbeddingSim)          (None, 128, 32000)   32000       FeedForward-Normal-12[1][0]      \n",
            "                                                                 Embed-Token[0][1]                \n",
            "==================================================================================================\n",
            "Total params: 211,122,176\n",
            "Trainable params: 116,750,336\n",
            "Non-trainable params: 94,371,840\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhbEE-wbIlkI",
        "outputId": "eba8d8b5-065f-4c45-f885-d080fcfa2682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbS1IytUOPwP",
        "outputId": "09e836f5-37bb-4bf8-bcd7-c24adcfe693b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  quora-question-pairs.zip\n",
            "  inflating: sample_submission.csv.zip  \n",
            "  inflating: test.csv                \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n",
            "Archive:  test.csv.zip\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqfyoveuOb2v",
        "outputId": "1c303d18-eec1-4d55-98eb-b91f8d1c0566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 16.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=0e070067a453b113a37f4c136fc7e5c8a0fa84abeb75049d6ea5efc1f520a1c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsr9IKIjNh86",
        "outputId": "6d1436d2-b6af-405f-8774-93317a8325f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gffdc42pNVOi"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import random \n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "# classification metric\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNGib9CFPqEO"
      },
      "source": [
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHESpUbZP3H4"
      },
      "source": [
        "seed=42\n",
        "seed_all(seed)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ZZBef1Vbch",
        "outputId": "d05cc708-681e-4060-adfa-fe07be503b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "train[\"question1\"] = train[\"question1\"].astype(str)\n",
        "train[\"question2\"] = train[\"question2\"].astype(str)\n",
        "\n",
        "print(train.shape,test.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404290, 6) (2345796, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-b6P1bDVs6I"
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "}"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZrJWCtWVuE4"
      },
      "source": [
        "# Parameters\n",
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 8\n",
        "\n",
        "model_type = 'roberta'\n",
        "pretrained_model_name = 'roberta-base' # 'roberta-base-openai-detector'"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRl9OC6RVzfh"
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuz9jyPJV13W",
        "outputId": "35bfbf96-2891-4593-fec4-86414e542ac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "910514051cc84c30bbc785ae647a9d72",
            "994f38cac6d64db79ed5497480fe8b7c",
            "3c786f6b961f4914bfd847495c944039",
            "a0f5ee8727514aa9901442943ee5e571",
            "c8ffab16fb664960bf75eb005e8f584e",
            "7210738490764c29af7ff58308ced052",
            "47fb959fafd640dab00d9f8d31c48353",
            "9d82abd3422f423080b849ebb8cf8a56",
            "1ed59628875c421c88c4cf7af2335e34",
            "d3440f34dd634285b83d2336e88013d6",
            "77744c5d989d4677a63fc0d08a946514",
            "b68d313205f04566be4177cf4d4fe99a",
            "d75b4d18a41f467292798c273b53a7e2",
            "e666a958ae11406796dc119c309b4725",
            "c53df7a616a7470287cc37229e0af06e",
            "ce21becb06614be98a8b178fb45c382b",
            "740ea6e48a5d4b1f8a8653c3a7fd22ae",
            "5ce993ef5a8141d49a441c3788056a72",
            "eded28a244e945c99fb7d2bba91b95fa",
            "531db42b57e74eaaa4c96eac45c108e4",
            "8a4451391ea34bb88e8574b9acc15ad0",
            "dc119c7cfb8f43a999a533603aabd2a9",
            "03222db84f544dfb84c8ab51fe533a2b",
            "c5ef44af575047ffbd07a7ce27e5766e",
            "e0dbefee80c14b20a68fd8c0af399156",
            "2d211938e65a4513a135b9ed2cd35d2f",
            "853444f825ee4d8a87077858b46ad943",
            "a4218f82068f4717887f7fa125be9343",
            "51d6128af2f942dfa72421c6065bd25f",
            "69f38eb6f75946929c1eb3ad5d73258c",
            "8e20cc6b2541476cb0ec15d9728e5d20",
            "abcccf3f81b3492aadc601e2c81ff1a6"
          ]
        }
      },
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "910514051cc84c30bbc785ae647a9d72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ed59628875c421c88c4cf7af2335e34",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "740ea6e48a5d4b1f8a8653c3a7fd22ae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0dbefee80c14b20a68fd8c0af399156",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dG_ExaHWRpP"
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "        return [CLS] + tokens + [SEP]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uew06NDPWarq",
        "outputId": "dc309f5f-794a-44ef-9051-351ff0cd4afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKWjVmVKWnr2"
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lqJX6EeWpRv"
      },
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96-tbAdaWtDH",
        "outputId": "7684f13f-cec2-4307-b480-0952353f5e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        }
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id\n",
        "databunch = (TextList.from_df(train, cols=['question1','question2'], processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols='is_duplicate')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X5gGmH-Y50R",
        "outputId": "dcaa12e3-2bb8-4c9a-836e-031acd3c6799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
        "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
        "print('[PAD] id :', pad_idx)\n",
        "test_one_batch = databunch.one_batch()[0]\n",
        "print('Batch shape : ',test_one_batch.shape)\n",
        "print(test_one_batch)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] id : 0\n",
            "[SEP] id : 2\n",
            "[PAD] id : 1\n",
            "Batch shape :  torch.Size([8, 313])\n",
            "tensor([[    0,   653,   222,  ...,  1144,   116,     2],\n",
            "        [    0,   286, 18947,  ...,     1,     1,     1],\n",
            "        [    0,    38,    74,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,  1336,   473,  ...,     1,     1,     1],\n",
            "        [    0,    38,   437,  ...,     1,     1,     1],\n",
            "        [    0,  1336,   109,  ...,     1,     1,     1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCSoitIMcmfs"
      },
      "source": [
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        attention_mask = (input_ids!=1).type(input_ids.type()) # attention_mask for RoBERTa\n",
        "            \n",
        "        logits = self.transformer(input_ids,\n",
        "                                attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAVj3doRc4co"
      },
      "source": [
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhfNJzt3dOIj"
      },
      "source": [
        "class AvgSpearman(Callback):\n",
        "    \n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.preds = np.empty( shape=(0, 30) )\n",
        "        self.target = np.empty( shape=(0, 30) )\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        self.preds = np.append(self.preds,last_output,axis=0)\n",
        "        self.target = np.append(self.target,last_target,axis=0)\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        spearsum = 0\n",
        "        for col in range(self.preds.shape[1]):\n",
        "            spearsum += spearmanr(self.preds[:,col],self.target[:,col]).correlation\n",
        "        res = spearsum / (self.preds.shape[1] + 1)\n",
        "        return add_metrics(last_metrics, res)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61sCWi-FdSMU"
      },
      "source": [
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = lambda input: AdamW(input,correct_bias=False), \n",
        "                  metrics=[AvgSpearman()])\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esioZ6DRdbMC",
        "outputId": "002b6272-5788-4fa4-d3ca-aeb4963fcd28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(learner.model)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CustomTransformerModel(\n",
            "  (transformer): RobertaForSequenceClassification(\n",
            "    (roberta): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "        (token_type_embeddings): Embedding(1, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): RobertaEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (classifier): RobertaClassificationHead(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwtH9FlBfBd9",
        "outputId": "bc690888-5502-49d7-9378-d0d839b63125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learner split in 1 groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6dPnEtCiCcc",
        "outputId": "8e029d57-2d28-4b3f-a91b-3e2544eb4325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(learner.model.transformer.roberta.pooler)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90i4e8rqfXvh",
        "outputId": "c71b215e-d485-48ba-a95b-0cfa8594ed6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "list_layers = [learner.model.transformer.roberta.embeddings,\n",
        "              learner.model.transformer.roberta.encoder.layer[0],\n",
        "              learner.model.transformer.roberta.encoder.layer[1],\n",
        "              learner.model.transformer.roberta.encoder.layer[2],\n",
        "              learner.model.transformer.roberta.encoder.layer[3],\n",
        "              learner.model.transformer.roberta.encoder.layer[4],\n",
        "              learner.model.transformer.roberta.encoder.layer[5],\n",
        "              learner.model.transformer.roberta.encoder.layer[6],\n",
        "              learner.model.transformer.roberta.encoder.layer[7],\n",
        "              learner.model.transformer.roberta.encoder.layer[8],\n",
        "              learner.model.transformer.roberta.encoder.layer[9],\n",
        "              learner.model.transformer.roberta.encoder.layer[10],\n",
        "              learner.model.transformer.roberta.encoder.layer[11]]\n",
        "print(list_layers)\n",
        "learner.split(list_layers);"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[RobertaEmbeddings(\n",
            "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "  (token_type_embeddings): Embedding(1, 768)\n",
            "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "), RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybZHWJCsdvw0",
        "outputId": "d1f34994-f5c3-451f-b9c5-dc30fd0c57e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "learner.recorder.plot(skip_end=7,suggestion=True)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-1af007439b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuggestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Learner' object has no attribute 'recorder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVej6LVwdf-3"
      },
      "source": [
        "seed_all(seed)\n",
        "learner.freeze_to(-1)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb_Gq13ieCNn"
      },
      "source": [
        "unfreeze_layers = [-1,-2,-3,-4,-5,-7]\n",
        "learning_rates = [2e-4, 5e-5, 1e-5, 5e-6, 1e-6,5e-7]\n",
        "epochs = [6, 5, 5, 5, 7, 7]"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ql6pgQOeDzF"
      },
      "source": [
        "def model_unfreezing_and_training():\n",
        "    for layer in range(0,len(unfreeze_layers)):\n",
        "        learner.freeze_to(unfreeze_layers[layer])\n",
        "        print('freezing to:',unfreeze_layers[layer],' - ',epochs[layer],'epochs')\n",
        "        learner.fit_one_cycle(epochs[layer], \n",
        "                              max_lr=slice(learning_rates[layer]*0.95**num_groups, learning_rates[layer]),\n",
        "                              moms=(0.8, 0.9))\n",
        "        learner.save('cycle_'+str(layer))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfwittSNeGFi",
        "outputId": "a035cfcb-e9b5-4317-daa5-99891c4a5b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "model_unfreezing_and_training()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "freezing to: -1  -  6 epochs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/6 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>avg_spearman</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='14408' class='' max='45482' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      31.68% [14408/45482 3:47:27<8:10:33 0.4027]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}